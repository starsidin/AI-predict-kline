import numpy as np
import pandas as pd
from typing import Tuple

EXPECTED_COLUMNS = [
    "datetime",
    "timestamp",
    "close",
    "high",
    "log_ret_scaled",
    "hl_range_scaled",
    "vol_z_scaled",
    "atr_norm_scaled",
    "log_ret_std_scaled",
    "ema_ratio_scaled",
    "rsi_norm_scaled",
    "macd_delta_norm_scaled",
    "hour_sin",
    "hour_cos",
    "dow_sin",
    "dow_cos",
    "dom_sin",
    "dom_cos",
    "month_sin",
    "month_cos",
]

PRICE_CLOSE_COLUMN = "close"
PRICE_HIGH_COLUMN = "high"
NON_FEATURE_COLUMNS = {"datetime", "timestamp", PRICE_CLOSE_COLUMN, PRICE_HIGH_COLUMN}

FEATURE_COLUMNS = [
    col for col in EXPECTED_COLUMNS if col not in NON_FEATURE_COLUMNS
]
TARGET_COLUMN = "log_ret_scaled"
DEFAULT_FUTURE_STEPS = 4
DEFAULT_TARGET_THRESHOLD = 0.01


def load_dual_branch_dataset(
    csv_path: str,
    seq_len: int = 20,
    test_ratio: float = 0.2,
    ma_4h_window: int = 16,
    ma_24h_window: int = 96,
    ma_4h_steps: int = 6,
    ma_24h_steps: int = 5,
    future_steps: int = DEFAULT_FUTURE_STEPS,
    target_threshold: float = DEFAULT_TARGET_THRESHOLD,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """Load dual-branch dataset using the real preprocessed features.

    The main branch uses sequential 15m features provided by the
    preprocessing pipeline. The auxiliary branch is built by computing
    rolling averages of the *actual* ``log_ret_scaled`` values over
    4-hour and 24-hour windows, avoiding any synthetic price series.

    Labels are generated by checking whether the maximum ``high`` price
    within the next ``future_steps`` candles exceeds the current
    ``close`` price by more than ``target_threshold`` (e.g. 1%).
    """

    if future_steps <= 0:
        raise ValueError("future_steps must be a positive integer")

    df = pd.read_csv(csv_path)
    df = df.sort_values("timestamp").reset_index(drop=True)

    missing_cols = [col for col in EXPECTED_COLUMNS if col not in df.columns]
    if missing_cols:
        raise ValueError(
            f"数据集中缺少以下列: {', '.join(missing_cols)}"
        )

    data_main = df[FEATURE_COLUMNS].to_numpy(dtype=np.float32)
    target_series = df[TARGET_COLUMN].astype(np.float32)
    close_series = df[PRICE_CLOSE_COLUMN].astype(np.float32)
    high_series = df[PRICE_HIGH_COLUMN].astype(np.float32)

    # Auxiliary branch uses real rolling statistics of the log returns
    ma_4h = target_series.rolling(window=ma_4h_window).mean()
    ma_24h = target_series.rolling(window=ma_24h_window).mean()
    ma_total_steps = ma_4h_steps + ma_24h_steps

    X_main, X_aux, y = [], [], []
    start_idx = max(
        seq_len - 1,
        ma_4h_window + ma_4h_steps - 2,
        ma_24h_window + ma_24h_steps - 2,
    )

    end_idx = len(df) - future_steps
    if end_idx <= start_idx:
        raise ValueError(
            "数据长度不足以生成未来窗口标签，请检查输入数据或 future_steps 设置"
        )

    for i in range(start_idx, end_idx):
        seq_main = data_main[i - seq_len + 1 : i + 1]
        if np.isnan(seq_main).any():
            continue

        seq4 = ma_4h.iloc[i - ma_4h_steps + 1 : i + 1].to_numpy(dtype=np.float32)
        seq24 = ma_24h.iloc[i - ma_24h_steps + 1 : i + 1].to_numpy(dtype=np.float32)
        if (
            seq4.shape[0] != ma_4h_steps
            or seq24.shape[0] != ma_24h_steps
            or np.isnan(seq4).any()
            or np.isnan(seq24).any()
        ):
            continue

        future_highs = high_series.iloc[i + 1 : i + 1 + future_steps]
        if future_highs.shape[0] < future_steps or np.isnan(future_highs).any():
            continue

        current_close = close_series.iloc[i]
        if np.isnan(current_close) or current_close <= 0:
            continue

        X_main.append(seq_main)
        aux_features = np.concatenate([seq4, seq24]).astype(np.float32)
        X_aux.append(aux_features.reshape(ma_total_steps, 1))
        max_future_high = float(future_highs.max())
        price_change = (max_future_high - float(current_close)) / float(current_close)
        y.append(int(price_change > target_threshold))

    X_main = np.array(X_main, dtype=np.float32)
    X_aux = np.array(X_aux, dtype=np.float32)
    y = np.array(y, dtype=np.int64)

    split_idx = int(len(X_main) * (1 - test_ratio))
    X_train_main, X_test_main = X_main[:split_idx], X_main[split_idx:]
    X_train_aux, X_test_aux = X_aux[:split_idx], X_aux[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    return X_train_main, X_train_aux, y_train, X_test_main, X_test_aux, y_test
